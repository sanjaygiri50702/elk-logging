# Input for Logstash is Kafka and the topic is "front"
# SSL certificate and SSL keys are generated using Open SSL
input {
   beats {
    port => 5044
    ssl => true
    ssl_certificate => "/usr/share/logstash/pipeline/logstash.crt"
    ssl_key => "/usr/share/logstash/pipeline/logstash.key"
  }
}


# Different filters can be applied to logs captured from different sources using tags
filter {
  if "pdf-service" in [tags] {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{DATA:source} - %{LOGLEVEL:loglevel} - %{GREEDYDATA:message}" }
    }
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }  
  if "backend-service" in [tags] {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{DATA:source} - %{LOGLEVEL:loglevel} - %{GREEDYDATA:message}" }
    }
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }  
}


# Output for Logstash is Elasticsearch and the indices are created based on date.
# Multiple indices can be created by checking the tags
output {
  if "pdf-service" in [tags] {
    elasticsearch {
      hosts => ["https://elasticsearch-es-http:9200"]
      user => "admin"
      password => "Admin@123"
      cacert => '/etc/logstash/certificates/ca.crt'
      ssl => true
      ssl_certificate_verification => true
      index => "pdf-service-logs-%{+YYYY-MM-dd}"
    }
  } 
  if "backend-service" in [tags] {
      elasticsearch {
      hosts => ["https://elasticsearch-es-http:9200"]
      user => "admin"
      password => "Admin@123"
      cacert => '/etc/logstash/certificates/ca.crt'
      ssl => true
      ssl_certificate_verification => true
      index => "backend-logs-%{+YYYY-MM-dd}"
    }
  } 
}